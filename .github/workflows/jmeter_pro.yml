name: JMeter Advanced Benchmark

on:
  workflow_dispatch:

jobs:
  jmeter-advanced-test:
    runs-on: ubuntu-latest

    steps:
      # -------------------------------------------------------
      # 1. Checkout repo
      # -------------------------------------------------------
      - name: ğŸ“¥ Checkout repo
        uses: actions/checkout@v4

      # -------------------------------------------------------
      # 2. Install JMeter
      # -------------------------------------------------------
      - name: ğŸ’¾ Install JMeter
        run: |
          wget https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-5.6.2.tgz
          tar -xzf apache-jmeter-5.6.2.tgz
          export JMETER_HOME="$PWD/apache-jmeter-5.6.2"
          echo "$JMETER_HOME/bin" >> $GITHUB_PATH

      # -------------------------------------------------------
      # 3. Install system monitoring tools
      # -------------------------------------------------------
      - name: ğŸ“¦ Install monitoring tools
        run: |
          sudo apt-get update
          sudo apt-get install -y sysstat gnuplot procps python3

      # -------------------------------------------------------
      # 4. Start monitors
      # -------------------------------------------------------
      - name: ğŸ§ª Start system metric monitors (CPU, MEM, Threads, System Load)
        run: |
          pidstat -durh 1 > pidstat.log &
          echo $! > pidstat_pid.txt

          (while true; do
            top -b -n1 | head -40 >> top.log
            echo "---" >> top.log
            sleep 2
          done) &
          echo $! > top_pid.txt

          (while true; do
            JMETER_PID=$(pgrep -f "ApacheJMeter" || true)
            if [ -n "$JMETER_PID" ]; then
              ps -T -p "$JMETER_PID" >> threads_raw.log 2>/dev/null
            fi
            sleep 1
          done) &
          echo $! > threads_pid.txt

      # -------------------------------------------------------
      # 5. Run JMeter
      # -------------------------------------------------------
      - name: ğŸš€ Run JMeter Advanced Load Test
        run: |
          echo "Running JMeter advanced test..."
          mkdir -p results

          /usr/bin/time -v \
            jmeter \
              -n \
              -t Jmeter/scripts/jmeter.jmx \
              -l results/jmeter_results.jtl \
              -e -o results/dashboard \
            2>&1 | tee jmeter.log

      # -------------------------------------------------------
      # 6. Stop monitors
      # -------------------------------------------------------
      - name: ğŸ›‘ Stop monitors
        if: always()
        run: |
          kill $(cat pidstat_pid.txt) || true
          kill $(cat top_pid.txt) || true
          kill $(cat threads_pid.txt) || true

      # -------------------------------------------------------
      # 7. Extract metrics
      # -------------------------------------------------------

      - name: ğŸ“Š Extract thread count timeline
        run: |
          grep -v "PID" threads_raw.log | awk '{print $1}' > threads.log
          awk '/java/ {print NR "," $1}' threads_raw.log > threads_timeline.csv

      - name: ğŸ“ˆ Extract latency list
        run: |
          awk -F',' 'NR>1 {print $2}' results/jmeter_results.jtl > latencies.txt

      - name: ğŸ“ˆ Extract latency timeline
        run: |
          awk -F',' 'NR>1 {print $1","$2}' results/jmeter_results.jtl > latency_timeline.csv

      - name: ğŸ“ˆ Compute p95 & p99
        run: |
          awk '{a[NR]=$1} END {
            asort(a)
            p95=a[int(NR*0.95)]
            p99=a[int(NR*0.99)]
            print "p95_ms="p95 > "latency_summary.txt"
            print "p99_ms="p99 >> "latency_summary.txt"
          }' latencies.txt

      - name: ğŸ“ˆ Extract RPS timeline
        run: |
          awk -F',' 'NR>1 {print int($1/1000)}' results/jmeter_results.jtl \
            | uniq -c \
            | awk '{print $2","$1}' > rps_timeline.csv

      - name: ğŸ“¦ Create jmeter_summary.json
        run: |
          python3 << 'EOF'
import csv, json

rows = list(csv.DictReader(open("results/jmeter_results.jtl")))
lat = [int(r["elapsed"]) for r in rows]

out = {
  "samples": len(lat),
  "avg_ms": sum(lat)/len(lat),
  "p95_ms": sorted(lat)[int(len(lat)*0.95)],
  "p99_ms": sorted(lat)[int(len(lat)*0.99)]
}

open("jmeter_summary.json","w").write(json.dumps(out, indent=2))
EOF

      # -------------------------------------------------------
      # 8. Upload ALL artifacts
      # -------------------------------------------------------
      - name: ğŸ“‚ Upload Advanced Benchmark Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: jmeter-advanced-results
          path: |
            jmeter.log
            pidstat.log
            top.log
            threads_raw.log
            threads.log
            threads_timeline.csv
            latencies.txt
            latency_timeline.csv
            latency_summary.txt
            rps_timeline.csv
            jmeter_summary.json
            time_metrics.txt
            results/
            Jmeter/scripts/jmeter.jmx
